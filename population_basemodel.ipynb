{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "f91b45585d66f8d42d8b427d8cc68ebdca9f95f539a3fd1ad17d4bc574d871b8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "SVM\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "ANNs\n",
    "\n",
    "KNN\n",
    "\n",
    "Decision Tree\n",
    "\n",
    "Naive Bayes\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "        number_words_title  number_words_content  rate_unique_words_content  \\\n0                     12.0                   219                   0.663594   \n1                      9.0                   255                   0.604743   \n2                      9.0                   211                   0.575130   \n3                      9.0                   531                   0.503788   \n4                     13.0                  1072                   0.415646   \n...                    ...                   ...                        ...   \n39639                 11.0                   346                   0.529052   \n39640                 12.0                   328                   0.696296   \n39641                 10.0                   442                   0.516355   \n39642                  6.0                   682                   0.539493   \n39643                 10.0                   157                   0.701987   \n\n       rate_non_stop_words_content  rate_unique_non_stop_words_content  \\\n0                              1.0                            0.815385   \n1                              1.0                            0.791946   \n2                              1.0                            0.663866   \n3                              1.0                            0.665635   \n4                              1.0                            0.540890   \n...                            ...                                 ...   \n39639                          1.0                            0.684783   \n39640                          1.0                            0.885057   \n39641                          1.0                            0.644128   \n39642                          1.0                            0.692661   \n39643                          1.0                            0.846154   \n\n       number_links   number_links_to_mashable   number_imgs   number_videos  \\\n0                 4                          2             1               0   \n1                 3                          1             1               0   \n2                 3                          1             1               0   \n3                 9                          0             1               0   \n4                19                         19            20               0   \n...             ...                        ...           ...             ...   \n39639             9                          7             1               1   \n39640             9                          7             3              48   \n39641            24                          1            12               1   \n39642            10                          1             1               0   \n39643             1                          1             0               2   \n\n        average_word_length  ...   min_polarity_in_positive_words  \\\n0                  4.680365  ...                         0.100000   \n1                  4.913725  ...                         0.033333   \n2                  4.393365  ...                         0.100000   \n3                  4.404896  ...                         0.136364   \n4                  4.682836  ...                         0.033333   \n...                     ...  ...                              ...   \n39639              4.523121  ...                         0.100000   \n39640              4.405488  ...                         0.136364   \n39641              5.076923  ...                         0.136364   \n39642              4.975073  ...                         0.062500   \n39643              4.471338  ...                         0.100000   \n\n        max_polarity_in_positive_words   avg_polarity_in_negative_words  \\\n0                                 0.70                        -0.350000   \n1                                 0.70                        -0.118750   \n2                                 1.00                        -0.466667   \n3                                 0.80                        -0.369697   \n4                                 1.00                        -0.220192   \n...                                ...                              ...   \n39639                             0.75                        -0.260000   \n39640                             0.70                        -0.211111   \n39641                             0.50                        -0.356439   \n39642                             0.50                        -0.205246   \n39643                             0.50                        -0.200000   \n\n        min_polarity_in_negative_words   max_polarity_in_negative_words  \\\n0                               -0.600                        -0.200000   \n1                               -0.125                        -0.100000   \n2                               -0.800                        -0.133333   \n3                               -0.600                        -0.166667   \n4                               -0.500                        -0.050000   \n...                                ...                              ...   \n39639                           -0.500                        -0.125000   \n39640                           -0.400                        -0.100000   \n39641                           -0.800                        -0.166667   \n39642                           -0.500                        -0.012500   \n39643                           -0.200                        -0.200000   \n\n        title_sentiment_subjectivity   title_sentiment_polarity  \\\n0                           0.500000                  -0.187500   \n1                           0.000000                   0.000000   \n2                           0.000000                   0.000000   \n3                           0.000000                   0.000000   \n4                           0.454545                   0.136364   \n...                              ...                        ...   \n39639                       0.100000                   0.000000   \n39640                       0.300000                   1.000000   \n39641                       0.454545                   0.136364   \n39642                       0.000000                   0.000000   \n39643                       0.333333                   0.250000   \n\n        abs_title_subjectivity   abs_title_sentiment_polarity   shares  \n0                     0.000000                       0.187500      593  \n1                     0.500000                       0.000000      711  \n2                     0.500000                       0.000000     1500  \n3                     0.500000                       0.000000     1200  \n4                     0.045455                       0.136364      505  \n...                        ...                            ...      ...  \n39639                 0.400000                       0.000000     1800  \n39640                 0.200000                       1.000000     1900  \n39641                 0.045455                       0.136364     1900  \n39642                 0.500000                       0.000000     1100  \n39643                 0.166667                       0.250000     1300  \n\n[39634 rows x 59 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number_words_title</th>\n      <th>number_words_content</th>\n      <th>rate_unique_words_content</th>\n      <th>rate_non_stop_words_content</th>\n      <th>rate_unique_non_stop_words_content</th>\n      <th>number_links</th>\n      <th>number_links_to_mashable</th>\n      <th>number_imgs</th>\n      <th>number_videos</th>\n      <th>average_word_length</th>\n      <th>...</th>\n      <th>min_polarity_in_positive_words</th>\n      <th>max_polarity_in_positive_words</th>\n      <th>avg_polarity_in_negative_words</th>\n      <th>min_polarity_in_negative_words</th>\n      <th>max_polarity_in_negative_words</th>\n      <th>title_sentiment_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.0</td>\n      <td>219</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.680365</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>0.70</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>255</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.913725</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>0.70</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>711</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>211</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.393365</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>1.00</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.0</td>\n      <td>531</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.404896</td>\n      <td>...</td>\n      <td>0.136364</td>\n      <td>0.80</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.0</td>\n      <td>1072</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19</td>\n      <td>19</td>\n      <td>20</td>\n      <td>0</td>\n      <td>4.682836</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>1.00</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>505</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39639</th>\n      <td>11.0</td>\n      <td>346</td>\n      <td>0.529052</td>\n      <td>1.0</td>\n      <td>0.684783</td>\n      <td>9</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.523121</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>0.75</td>\n      <td>-0.260000</td>\n      <td>-0.500</td>\n      <td>-0.125000</td>\n      <td>0.100000</td>\n      <td>0.000000</td>\n      <td>0.400000</td>\n      <td>0.000000</td>\n      <td>1800</td>\n    </tr>\n    <tr>\n      <th>39640</th>\n      <td>12.0</td>\n      <td>328</td>\n      <td>0.696296</td>\n      <td>1.0</td>\n      <td>0.885057</td>\n      <td>9</td>\n      <td>7</td>\n      <td>3</td>\n      <td>48</td>\n      <td>4.405488</td>\n      <td>...</td>\n      <td>0.136364</td>\n      <td>0.70</td>\n      <td>-0.211111</td>\n      <td>-0.400</td>\n      <td>-0.100000</td>\n      <td>0.300000</td>\n      <td>1.000000</td>\n      <td>0.200000</td>\n      <td>1.000000</td>\n      <td>1900</td>\n    </tr>\n    <tr>\n      <th>39641</th>\n      <td>10.0</td>\n      <td>442</td>\n      <td>0.516355</td>\n      <td>1.0</td>\n      <td>0.644128</td>\n      <td>24</td>\n      <td>1</td>\n      <td>12</td>\n      <td>1</td>\n      <td>5.076923</td>\n      <td>...</td>\n      <td>0.136364</td>\n      <td>0.50</td>\n      <td>-0.356439</td>\n      <td>-0.800</td>\n      <td>-0.166667</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>1900</td>\n    </tr>\n    <tr>\n      <th>39642</th>\n      <td>6.0</td>\n      <td>682</td>\n      <td>0.539493</td>\n      <td>1.0</td>\n      <td>0.692661</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.975073</td>\n      <td>...</td>\n      <td>0.062500</td>\n      <td>0.50</td>\n      <td>-0.205246</td>\n      <td>-0.500</td>\n      <td>-0.012500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1100</td>\n    </tr>\n    <tr>\n      <th>39643</th>\n      <td>10.0</td>\n      <td>157</td>\n      <td>0.701987</td>\n      <td>1.0</td>\n      <td>0.846154</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4.471338</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>0.50</td>\n      <td>-0.200000</td>\n      <td>-0.200</td>\n      <td>-0.200000</td>\n      <td>0.333333</td>\n      <td>0.250000</td>\n      <td>0.166667</td>\n      <td>0.250000</td>\n      <td>1300</td>\n    </tr>\n  </tbody>\n</table>\n<p>39634 rows × 59 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from datasets import popularity_dataset\n",
    "import pandas as pd\n",
    "popularity_data = popularity_dataset().dropna().drop('days_article_dataset', axis=1)\n",
    "\n",
    "display(popularity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median = popularity_data.median()[' shares']\n",
    "# display(median)\n",
    "\n",
    "# threshold = median\n",
    "# popularity_data.loc[popularity_data[' shares'] > threshold, 'will be successfull'] = 1\n",
    "# popularity_data.loc[popularity_data[' shares'] <= threshold, 'will be successfull'] = 0\n",
    "# display(popularity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data(original_data):\n",
    "    return original_data.sample(frac=.2, random_state=1)\n",
    "data = get_sample_data(popularity_data)"
   ]
  },
  {
   "source": [
    "As discussed and proposed by exploration team, we should find a way to discretize the values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_cutpoints_for_percent\n",
    "classes = ['Very Bad', 'Bad', 'Moderate', 'Good', 'Very Good']\n",
    "\n",
    "sorted_shares = data.sort_values(by=' shares', ascending= True)\n",
    "\n",
    "classes_cutpoints = [\n",
    "    get_cutpoints_for_percent(sorted_shares, 0, .3, ' shares'),\n",
    "    get_cutpoints_for_percent(sorted_shares, .3, .5, ' shares'),\n",
    "    get_cutpoints_for_percent(sorted_shares, .5, .8, ' shares'),\n",
    "    get_cutpoints_for_percent(sorted_shares, .8, .95, ' shares'),\n",
    "    get_cutpoints_for_percent(sorted_shares, .95, 1, ' shares'),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "        number_words_title  number_words_content  rate_unique_words_content  \\\n17387                  9.0                   222                   0.605634   \n34245                  8.0                   640                   0.455479   \n33543                 14.0                  3469                   0.226190   \n16694                  8.0                   108                   0.819048   \n37033                 14.0                   769                   0.420026   \n...                    ...                   ...                        ...   \n75                     6.0                   374                   0.640541   \n9211                  12.0                   203                   0.534392   \n6965                  10.0                   132                   0.696970   \n6298                  10.0                   406                   0.548128   \n39231                 11.0                   938                   0.469055   \n\n       rate_non_stop_words_content  rate_unique_non_stop_words_content  \\\n17387                          1.0                            0.723077   \n34245                          1.0                            0.549223   \n33543                          1.0                            0.425599   \n16694                          1.0                            0.939394   \n37033                          1.0                            0.627451   \n...                            ...                                 ...   \n75                             1.0                            0.828054   \n9211                           1.0                            0.610619   \n6965                           1.0                            0.835443   \n6298                           1.0                            0.676471   \n39231                          1.0                            0.628070   \n\n       number_links   number_links_to_mashable   number_imgs   number_videos  \\\n17387             9                          5             1               0   \n34245            21                          2             2               0   \n33543             6                          5             1               3   \n16694             2                          0             1               0   \n37033            17                          2             1               0   \n...             ...                        ...           ...             ...   \n75                7                          0             1               0   \n9211              1                          0             1               0   \n6965              3                          2             0               2   \n6298             22                          1            11               0   \n39231            20                         13             4               0   \n\n        average_word_length  ...   max_polarity_in_positive_words  \\\n17387              4.837838  ...                              0.6   \n34245              4.679688  ...                              1.0   \n33543              3.957336  ...                              1.0   \n16694              4.944444  ...                              0.5   \n37033              4.700910  ...                              1.0   \n...                     ...  ...                              ...   \n75                 4.909091  ...                              0.8   \n9211               4.251232  ...                              0.6   \n6965               4.590909  ...                              0.7   \n6298               4.460591  ...                              0.7   \n39231              4.861407  ...                              1.0   \n\n        avg_polarity_in_negative_words   min_polarity_in_negative_words  \\\n17387                        -0.200000                            -0.20   \n34245                        -0.319444                            -0.70   \n33543                        -0.332075                            -1.00   \n16694                        -0.300000                            -0.30   \n37033                        -0.157292                            -0.25   \n...                                ...                              ...   \n75                           -0.130357                            -0.20   \n9211                         -0.400000                            -0.40   \n6965                         -0.522222                            -0.90   \n6298                         -0.180833                            -0.50   \n39231                        -0.233876                            -0.80   \n\n        max_polarity_in_negative_words   title_sentiment_subjectivity  \\\n17387                        -0.200000                       0.000000   \n34245                        -0.100000                       0.733333   \n33543                        -0.071429                       0.000000   \n16694                        -0.300000                       1.000000   \n37033                        -0.050000                       0.183333   \n...                                ...                            ...   \n75                           -0.050000                       0.000000   \n9211                         -0.400000                       0.500000   \n6965                         -0.300000                       0.000000   \n6298                         -0.050000                       1.000000   \n39231                        -0.050000                       0.000000   \n\n        title_sentiment_polarity   abs_title_subjectivity  \\\n17387                   0.000000                 0.500000   \n34245                   0.033333                 0.233333   \n33543                   0.000000                 0.500000   \n16694                   0.000000                 0.500000   \n37033                   0.516667                 0.316667   \n...                          ...                      ...   \n75                      0.000000                 0.500000   \n9211                    0.000000                 0.000000   \n6965                    0.000000                 0.500000   \n6298                    0.200000                 0.500000   \n39231                   0.000000                 0.500000   \n\n        abs_title_sentiment_polarity   shares  share_class  \n17387                       0.000000      990     Very Bad  \n34245                       0.033333     3000          Bad  \n33543                       0.000000     1500          Bad  \n16694                       0.000000      589     Very Bad  \n37033                       0.516667     2000          Bad  \n...                              ...      ...          ...  \n75                          0.000000      552     Very Bad  \n9211                        0.000000     2900          Bad  \n6965                        0.000000     3000          Bad  \n6298                        0.200000     2300          Bad  \n39231                       0.000000     3000          Bad  \n\n[7927 rows x 60 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number_words_title</th>\n      <th>number_words_content</th>\n      <th>rate_unique_words_content</th>\n      <th>rate_non_stop_words_content</th>\n      <th>rate_unique_non_stop_words_content</th>\n      <th>number_links</th>\n      <th>number_links_to_mashable</th>\n      <th>number_imgs</th>\n      <th>number_videos</th>\n      <th>average_word_length</th>\n      <th>...</th>\n      <th>max_polarity_in_positive_words</th>\n      <th>avg_polarity_in_negative_words</th>\n      <th>min_polarity_in_negative_words</th>\n      <th>max_polarity_in_negative_words</th>\n      <th>title_sentiment_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n      <th>share_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17387</th>\n      <td>9.0</td>\n      <td>222</td>\n      <td>0.605634</td>\n      <td>1.0</td>\n      <td>0.723077</td>\n      <td>9</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.837838</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>-0.200000</td>\n      <td>-0.20</td>\n      <td>-0.200000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>990</td>\n      <td>Very Bad</td>\n    </tr>\n    <tr>\n      <th>34245</th>\n      <td>8.0</td>\n      <td>640</td>\n      <td>0.455479</td>\n      <td>1.0</td>\n      <td>0.549223</td>\n      <td>21</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4.679688</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.319444</td>\n      <td>-0.70</td>\n      <td>-0.100000</td>\n      <td>0.733333</td>\n      <td>0.033333</td>\n      <td>0.233333</td>\n      <td>0.033333</td>\n      <td>3000</td>\n      <td>Bad</td>\n    </tr>\n    <tr>\n      <th>33543</th>\n      <td>14.0</td>\n      <td>3469</td>\n      <td>0.226190</td>\n      <td>1.0</td>\n      <td>0.425599</td>\n      <td>6</td>\n      <td>5</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3.957336</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.332075</td>\n      <td>-1.00</td>\n      <td>-0.071429</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500</td>\n      <td>Bad</td>\n    </tr>\n    <tr>\n      <th>16694</th>\n      <td>8.0</td>\n      <td>108</td>\n      <td>0.819048</td>\n      <td>1.0</td>\n      <td>0.939394</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.944444</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>-0.300000</td>\n      <td>-0.30</td>\n      <td>-0.300000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>589</td>\n      <td>Very Bad</td>\n    </tr>\n    <tr>\n      <th>37033</th>\n      <td>14.0</td>\n      <td>769</td>\n      <td>0.420026</td>\n      <td>1.0</td>\n      <td>0.627451</td>\n      <td>17</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.700910</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.157292</td>\n      <td>-0.25</td>\n      <td>-0.050000</td>\n      <td>0.183333</td>\n      <td>0.516667</td>\n      <td>0.316667</td>\n      <td>0.516667</td>\n      <td>2000</td>\n      <td>Bad</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>6.0</td>\n      <td>374</td>\n      <td>0.640541</td>\n      <td>1.0</td>\n      <td>0.828054</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.909091</td>\n      <td>...</td>\n      <td>0.8</td>\n      <td>-0.130357</td>\n      <td>-0.20</td>\n      <td>-0.050000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>552</td>\n      <td>Very Bad</td>\n    </tr>\n    <tr>\n      <th>9211</th>\n      <td>12.0</td>\n      <td>203</td>\n      <td>0.534392</td>\n      <td>1.0</td>\n      <td>0.610619</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4.251232</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>-0.400000</td>\n      <td>-0.40</td>\n      <td>-0.400000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2900</td>\n      <td>Bad</td>\n    </tr>\n    <tr>\n      <th>6965</th>\n      <td>10.0</td>\n      <td>132</td>\n      <td>0.696970</td>\n      <td>1.0</td>\n      <td>0.835443</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4.590909</td>\n      <td>...</td>\n      <td>0.7</td>\n      <td>-0.522222</td>\n      <td>-0.90</td>\n      <td>-0.300000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>3000</td>\n      <td>Bad</td>\n    </tr>\n    <tr>\n      <th>6298</th>\n      <td>10.0</td>\n      <td>406</td>\n      <td>0.548128</td>\n      <td>1.0</td>\n      <td>0.676471</td>\n      <td>22</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0</td>\n      <td>4.460591</td>\n      <td>...</td>\n      <td>0.7</td>\n      <td>-0.180833</td>\n      <td>-0.50</td>\n      <td>-0.050000</td>\n      <td>1.000000</td>\n      <td>0.200000</td>\n      <td>0.500000</td>\n      <td>0.200000</td>\n      <td>2300</td>\n      <td>Bad</td>\n    </tr>\n    <tr>\n      <th>39231</th>\n      <td>11.0</td>\n      <td>938</td>\n      <td>0.469055</td>\n      <td>1.0</td>\n      <td>0.628070</td>\n      <td>20</td>\n      <td>13</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4.861407</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.233876</td>\n      <td>-0.80</td>\n      <td>-0.050000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>3000</td>\n      <td>Bad</td>\n    </tr>\n  </tbody>\n</table>\n<p>7927 rows × 60 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from datasets import get_class_for_value\n",
    "data['share_class'] = data.apply(lambda row: get_class_for_value(row[' shares'], classes_cutpoints, classes), axis=1)\n",
    "display(data)"
   ]
  },
  {
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import pandas as pd\n",
    "\n",
    "est = KBinsDiscretizer(n_bins=5, encode='ordinal')\n",
    "Xt = est.fit_transform(data[[' shares']])\n",
    "\n",
    "newDf = data.copy(deep=True)\n",
    "newDf['alt_share_class'] = Xt\n",
    "newDf['alt_share_class'] = newDf.apply(lambda row: classes[int(row['alt_share_class'])], axis=1)\n",
    "\n",
    "data['alt_share_class'] = newDf['alt_share_class']"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['share_class'] = data.apply(lambda row: classes.index(row['share_class']), axis=1)\n",
    "x = data.drop(' shares', axis=1).drop('alt_share_class', axis=1).drop('share_class', axis=1).dropna()\n",
    "y = data['share_class'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "def calculate_kfold(clf, x, y):\n",
    "    skf = StratifiedKFold(n_splits = 2)\n",
    "    i=1\n",
    "    for train_index,test_index in skf.split(x,y):\n",
    "        print('{} of KFold {}'.format(i,skf.n_splits))\n",
    "        xtr,xvl = x.reindex(index = train_index),x.reindex(index = test_index)\n",
    "        ytr,yvl = y.reindex(index = train_index),y.reindex(index = test_index)\n",
    "    \n",
    "        #model\n",
    "        clf.fit(xtr,ytr)\n",
    "        score = roc_auc_score(yvl,clf.predict(xvl))\n",
    "        print('ROC AUC score:',score)\n",
    "        i+=1\n",
    "\n",
    "def get_ann_score(clf, x,y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return (clf.score(x_test,y_test), classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0b0e8260eb40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mannClf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mannScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannClf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy ANN: %0.2f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mannScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \"\"\"\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>"
     ]
    }
   ],
   "source": [
    "from datasets import accuracy_score\n",
    "\n",
    "annClf = MLPClassifier(hidden_layer_sizes=(5, 2), random_state=1)\n",
    "annScore = accuracy_score(annClf,x,y)\n",
    "print(\"Accuracy ANN: %0.2f\" % annScore)\n",
    "\n",
    "annClf = MLPClassifier(hidden_layer_sizes=(50, 50), random_state=1)\n",
    "annScore = accuracy_score(annClf,x,y)\n",
    "print(\"Accuracy ANN: %0.2f\" % annScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy SVM: 0.52\n",
      "Accuracy Logistic Regression: 0.51\n",
      "Accuracy KNN: 0.45\n",
      "Accuracy Naive Bayes: 0.49\n",
      "Accuracy Decision Tree: 0.41\n",
      "Accuracy ANN: 0.32\n"
     ]
    }
   ],
   "source": [
    "from datasets import calculate_scores\n",
    "\n",
    "calculate_scores(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}